{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 for LING413 \n",
    "##### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Formatting Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country                                              Tweet\n",
      "1  Australia  all the evidence anyone should need to know th...\n",
      "2  Australia  over the birds of the heavens and over the liv...\n",
      "3  Australia  biggest present under the tree is for me from ...\n",
      "4  Australia  my boyfriend got me a diamond bracelet and his...\n",
      "5  Australia  should spend more time covering your own ass b...\n",
      "(200000, 2)\n"
     ]
    }
   ],
   "source": [
    "file = \"Twitter_by_country.gz\"\n",
    "\n",
    "n = 1140248 # num samples in file\n",
    "s = 200000 # num samples to use\n",
    "\n",
    "skip = sorted(random.sample(range(n), n-s))\n",
    "\n",
    "data_df = pd.read_csv(file, sep = \",\", header = None, skiprows=skip)\n",
    "data_df.drop(0, axis = 1, inplace = True)\n",
    "data_df.drop(0, axis = 0, inplace = True)\n",
    "data_df.columns = [\"Country\", \"Tweet\"]\n",
    "\n",
    "print(data_df.head())\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extraction.text.CountVectorizer(input='content', \n",
    "                                                encoding='utf-8',\n",
    "                                                lowercase=True, \n",
    "                                                tokenizer = None,\n",
    "                                                ngram_range=(1, 1), \n",
    "                                                analyzer='word',\n",
    "                                                max_features=10000, #This sets vocab size\n",
    "                                                )\n",
    "\n",
    "#Sklearn first fits then transforms\n",
    "features.fit(data_df.loc[:,\"Tweet\"])\n",
    "data_x = features.transform(data_df.loc[:,\"Tweet\"])\n",
    "data_y = data_df.loc[:,\"Country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (180000, 10000) (180000,)\n",
      "Test shape (20000, 10000) (20000,)\n",
      "LogisticRegression(max_iter=4000)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.10, shuffle=True)\n",
    "\n",
    "print(\"Train shape\", x_train.shape, y_train.shape)\n",
    "print(\"Test shape\", x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "cls = LogisticRegression(max_iter=4000)\n",
    "cls.fit(x_train, y_train)\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Australia       0.88      0.88      0.88      3350\n",
      "       Ireland       0.91      0.91      0.91      3386\n",
      "   New_Zealand       0.86      0.86      0.86      3125\n",
      "  South_Africa       0.95      0.95      0.95      3404\n",
      "United_Kingdom       0.88      0.88      0.88      3367\n",
      " United_States       0.92      0.92      0.92      3368\n",
      "\n",
      "      accuracy                           0.90     20000\n",
      "     macro avg       0.90      0.90      0.90     20000\n",
      "  weighted avg       0.90      0.90      0.90     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cls.predict(x_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "with codecs.open(\"unigram_tweet_classification_results.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model for Later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unigram_tweet_classification_model.p\", \"wb\") as handle:\n",
    "    pickle.dump(cls, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
